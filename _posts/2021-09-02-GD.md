# Local Gradients, Evolution, and Sexual Selection Stream of Thoughts

What is the difference between backpropogation and evolution? Both take small steps in parameter space that seek an improvement in some objective function of a system's inputs. I don't want to get confused with the idea that a neural net can approximate any function. In the case of approximating a function, the objective function is just the difference between the nets output and the function to approximate. We should imagine this objective function as a continuous manifold over a parameter space. One way I imagine this is as 3D surface over a 2D parameter space, but I sometimes also imagine a high-dimensional parameter space like a 3D grid with a color dimension at each point and a corresponding number line with a tickmark that represents the value of the objective function. As parameters are varried in the high dimensional parameter space, the tick mark wiggles with varrying degrees of response to a unit impulse in a certain parameter. This is approximately visualizing the derivative of of the objective function with respect each parameter. The comparative magnitudes of the wiggles gives us the combination of directions that points in the direction of greatest increase. The difference between gradient descent and evolution is that GD approximates the direction of greatest increase by using the instantaneous derivative whereas evolution explores the actual effects of moving in a random direction in parameter space. It is easy to imagine how discontinuities in an objective function might fool this approximation, and it is possible to construe relevant discontinuous objective functions. For example, imagine optimizing the speed and purchse price of a computer. There is a large region of parameter space where the derivative of every variable (number of cores, temperature, etc.) would be zero because the number of dollars would not be high enough to buy even the cheapest computer. However, once the ammount of money needed is surpased there will be a discontinuous jump in speed away from zero. In other words, gradient descent does not take too large a risk because it relies on its confidence in the small local region it can approximate. Evolution may go out on a limb due to random mutation and discover new productive regions of parameter space. I am sure modern optimizers implement techniques that account for this sort of thing, but those are fancy add ons to the core principle of gradient descent. 

Benefits of evolution:

* an algorithm that is more naturally aligned with the principle of computational equivilence
* cannot be fooled by discontinuities or non-differentiable points in the objective function
* can perform optimization over discrete domains and pseudo continuous domains simultaneously
* is very naturally parallelizable

Drawbacks:

1. exploring random directions is computationally expensive... countless life-forms died to get to homo sapiens
2. Random change is not condusive to dedicated chipset because the mathematical structure of the forward pass could change. Perhaps graph neural networks have an answer here...

## Sexual Selection Forray
 
Mating and sexual preference is an amplifier on objective function signal to the evolutionary algorithm. Using the pockets of reducibility in the computational task of estimating the objective function, computational agents can sexually select traits that in their estimation increase the objective function. For example, it is clear that if a mutation occures that makes someone 20% stronger, instead of waiting for competition between that gene line and another gene line to resolve in survival of the fittest, a computational agent can immediately reward that change by making it easier for it to reproduce and therefore continue to exist. This is a massive accelerator for an evolutionary algorithm, and it doesn't necessarily have to come from sexual selection. What must be done is a study of the objective function that can extract the principle predictable dimensions. For example, in the field of drug discovery, many ML algorithms are aided by the many heuristics about chemical structure and binding that have been discovered by human researchers. This analysis can also be performed on combinations of dimensions. For example, in the strength example, no single axis in the space of DNA sequences leads to more strength, but computational agents can invent scalar axis that are in reality conglomerations of smaller dimensions. To be more formal, these are functions of parameter space that have a simple/reducible functional relationship to the objective function. These helper functions could potentially be approximated by neural nets. Finding these functions seems like a sort of principle component analysis... In a way, you are finding functional transformations of parameter space that yield simple and signifigant relationships on some special direction in parameter space. There are eigan direction connections here. Perhaps using a variable reduction net tequnique could tease out the dimensions in which the effects on objective function are reducible? This would take the form of compressing the input vector into minimal vector representation which then gets linearly-expanded into an output vector. In this net the dimension of the minimal representation is a hyper parameter. Another example of a dimension like this would be complexity of the solution where a higher complexity solution that achieves the same results as a simpler solution is worse. Another example could potentially be some sort of topological variables the specifics of which could be discovered on a case by case basis.

## Back to Evolution

Evolution is such an interesting algorithm because it is emergent out of pure chaos. As high dimensional systems percolate through time, completely random and unpredictable patterns will innevitably emerge as discovered by Steven Wolfram. However, in all this randomness something else emerges: self repeating patterns. The existence of these patterns creates an implicit objective function: existence. Patterns that successfully repeat themselves will live on, whereas patterns that do not repeat themselves will die forever. So, these self replicating patterns eventually emerge which is where evolution starts to tweak the pattern that is self replicated such that it is more resilient to environmental factors that could end the pattern. The biggest difficulty I see in doing this is creating a pattern that is highly changeable, but always repeatable. This is why the combination of DNA and the cell wall is such an incredible self repeating pattern. Using celular automata, you can create structures that self replicate, however changing any part of that structure would change replication mechanism and ruin the pattern. However, the particular structure of our cells allows the replication process to independent of all the other protien recipes that are encoded in our DNA. In this way DNA implements modularity in its code such that changing something in one region of instructions will not alter things all over the program. Of course the reason for this is that it if did not happen this way, random mutations in code brought on by ionizing radiation or copy errors would kill or drastically alter the entire pattern. Modular code allows random changes to alter sub systems that may have a positive or negative effect on the overall program function. From a developer perspective, bugs could be considered as random ionizing radiation that carries a negative effect to the program. The jury is out on whether combination with the mitochondria was the final piece in the puzzle of a productive cellular structure. It seems like having a stable energy source would be essential for evolution to run smoothly. Not long after this flexible substrate is instantiated, rapid ammounts of evolution can happen pretty easily. That is why I think the deffinition of life should be a pattern that implements some sort of self replicating cell or at least something with the same properties of modular information storage, entropy resistent wall, and an ability to self replicate. 

Eventually evolution gets around to generating elementary computers that run on top of the underlying universal computation machine that renders matter and energy, kind of like running multiple virtual machines on a single CPU. Computation became steadily more sophisticated until it arrived at conciousness. I will talk about the journey from basic computational organisms to conciousness in another post. But now I will mention now that as soon as computation is realized, evolution begins finding little pockets of computational reducibility. For example, by processing light it can predict using shadow an oncoming threat. Using a fourier transform, which is implemented in the structure of our ear drums, organisms can predict whether an auditory signal is high frequency noise, or if a real low-frequency signal is nearby and demanding of attention. Sexual selection is just a way to use these pockets of reducibility to accelerate the evolutionary algorithm. To touch on this one more time, imagine how much longer it would have taken to arrive at certain dog breeds from wolves if we just indiscriminately killed dogs when we didn't like them. Our brains have the incredible ability to discover pockets of reducibility without evolution or random search... instead we use logic which is another key evolutionary invention. 

In general, evolution scales really well, can solve the hardest problems we can concieve of, and emerges naturally from the underlying computational laws of the universe. Of course it has its flaws. The classic example is the giraff neck which contains a vein that travels all the way from its head all the way down the neck and then back up again to deliver blood somewhere else in the head. This is clearly inneficient, however, it is a configuration of parameter space that solves the problem of reaching hard to reach leaves on trees. In this case however, it is quite hard for evolution to come up with a solution to the friction losses of pumping blood down and up the neck again. It must start generating a blood vessel that randomly works its way from somewhere on the vein and connect to somewhere else on the vein. This is hard because it must take a large number of steps in different dimensions without reward before it can work. Once connected, varying the size of the new vein loop would be relatively easy, but making the initial connection would be very difficult. As an aside, I am hopeful that some day, we will be able to understand the code of DNA well enough such that we have some sort of compiler that can transorm instructions like add a vein here into DNA assembly. The only way I can imagine doing it is creating a simulation of all the chemical reactions occuring in a cell which would be absurdly computationally impossible. Maybe alpha fold is an indication that we may someday be using compilers that utilize computational learning to edit the code of life. 

